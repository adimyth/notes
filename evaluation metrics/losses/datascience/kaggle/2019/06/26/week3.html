<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>How to win a data science competition (Week 3) | Notes</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="How to win a data science competition (Week 3)" />
<meta name="author" content="Aditya Mishra" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My personal notes of Coursera’s ‘How to win a data science competition’. This week, the instructors discuss in detail different classification &amp; regression metrics, as well as their advantages &amp; disadvantages." />
<meta property="og:description" content="My personal notes of Coursera’s ‘How to win a data science competition’. This week, the instructors discuss in detail different classification &amp; regression metrics, as well as their advantages &amp; disadvantages." />
<link rel="canonical" href="/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html" />
<meta property="og:url" content="/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html" />
<meta property="og:site_name" content="Notes" />
<meta property="og:image" content="/notes/images/metrics.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-06-26T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Aditya Mishra"},"description":"My personal notes of Coursera’s ‘How to win a data science competition’. This week, the instructors discuss in detail different classification &amp; regression metrics, as well as their advantages &amp; disadvantages.","@type":"BlogPosting","headline":"How to win a data science competition (Week 3)","dateModified":"2019-06-26T00:00:00-05:00","datePublished":"2019-06-26T00:00:00-05:00","image":"/notes/images/metrics.png","url":"/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html","mainEntityOfPage":{"@type":"WebPage","@id":"/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="/notes/feed.xml" title="Notes" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-140233777-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>How to win a data science competition (Week 3) | Notes</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="How to win a data science competition (Week 3)" />
<meta name="author" content="Aditya Mishra" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My personal notes of Coursera’s ‘How to win a data science competition’. This week, the instructors discuss in detail different classification &amp; regression metrics, as well as their advantages &amp; disadvantages." />
<meta property="og:description" content="My personal notes of Coursera’s ‘How to win a data science competition’. This week, the instructors discuss in detail different classification &amp; regression metrics, as well as their advantages &amp; disadvantages." />
<link rel="canonical" href="/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html" />
<meta property="og:url" content="/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html" />
<meta property="og:site_name" content="Notes" />
<meta property="og:image" content="/notes/images/metrics.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-06-26T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Aditya Mishra"},"description":"My personal notes of Coursera’s ‘How to win a data science competition’. This week, the instructors discuss in detail different classification &amp; regression metrics, as well as their advantages &amp; disadvantages.","@type":"BlogPosting","headline":"How to win a data science competition (Week 3)","dateModified":"2019-06-26T00:00:00-05:00","datePublished":"2019-06-26T00:00:00-05:00","image":"/notes/images/metrics.png","url":"/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html","mainEntityOfPage":{"@type":"WebPage","@id":"/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="/notes/feed.xml" title="Notes" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-140233777-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/notes/">Notes</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/notes/_pages/about.html">About Me</a><a class="page-link" href="/notes/search/">Search</a><a class="page-link" href="/notes/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How to win a data science competition (Week 3)</h1><p class="page-description">My personal notes of Coursera's 'How to win a data science competition'. This week, the instructors discuss in detail different classification & regression metrics, as well as their advantages & disadvantages.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2019-06-26T00:00:00-05:00" itemprop="datePublished">
        Jun 26, 2019
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Aditya Mishra</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#evaluation metrics">evaluation metrics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/notes/categories/#losses">losses</a>
        &nbsp;
      
        <a class="category-tags-link" href="/notes/categories/#datascience">datascience</a>
        &nbsp;
      
        <a class="category-tags-link" href="/notes/categories/#kaggle">kaggle</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#how-to-win-a-data-science-competition-week-3">How to win a data science competition (Week 3)</a>
<ul>
<li class="toc-entry toc-h2"><a href="#regression-metrics">Regression Metrics</a>
<ul>
<li class="toc-entry toc-h3"><a href="#mean-squared-error-mse">Mean Squared Error (MSE)</a></li>
<li class="toc-entry toc-h3"><a href="#root-mean-squared-error-rmse">Root Mean Squared Error (RMSE)</a></li>
<li class="toc-entry toc-h3"><a href="#r-squared">R-Squared</a></li>
<li class="toc-entry toc-h3"><a href="#mean-absolute-error-mae">Mean Absolute Error (MAE)</a></li>
<li class="toc-entry toc-h3"><a href="#mean-absolute-percentage-error-mape">Mean Absolute Percentage Error (MAPE)</a></li>
<li class="toc-entry toc-h3"><a href="#mean-squared-percentage-error-mspe">Mean Squared Percentage Error (MSPE)</a></li>
<li class="toc-entry toc-h3"><a href="#root-mean-square-logarithmic-error-rmsle">Root Mean Square Logarithmic Error (RMSLE)</a></li>
<li class="toc-entry toc-h3"><a href="#poisson-loss">Poisson Loss</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#regression-loss">Regression Loss</a>
<ul>
<li class="toc-entry toc-h3"><a href="#huber-loss">Huber Loss</a></li>
<li class="toc-entry toc-h3"><a href="#log-cosh-loss">Log Cosh Loss</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#classification-metrics">Classification Metrics</a>
<ul>
<li class="toc-entry toc-h3"><a href="#matthews-correlation-coefficient">Matthews Correlation Coefficient</a></li>
<li class="toc-entry toc-h3"><a href="#f1-score">F1-Score</a>
<ul>
<li class="toc-entry toc-h4"><a href="#precision">Precision</a></li>
<li class="toc-entry toc-h4"><a href="#recall">Recall</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#accuracy">Accuracy</a></li>
<li class="toc-entry toc-h3"><a href="#logloss">LogLoss</a></li>
<li class="toc-entry toc-h3"><a href="#auc-roc">AUC ROC</a>
<ul>
<li class="toc-entry toc-h4"><a href="#auc-roc-curve">AUC ROC Curve</a></li>
<li class="toc-entry toc-h4"><a href="#pairs-ordering">Pairs Ordering</a></li>
<li class="toc-entry toc-h4"><a href="#quiz">Quiz</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#cohens-kappa">Cohen’s Kappa</a>
<ul>
<li class="toc-entry toc-h4"><a href="#example">Example</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#quadratic-weighted-kappa">Quadratic Weighted Kappa</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#target--metric">Target &amp; Metric</a></li>
<li class="toc-entry toc-h2"><a href="#regression-metrics-optimization">Regression Metrics Optimization</a>
<ul>
<li class="toc-entry toc-h3"><a href="#mse">MSE</a></li>
<li class="toc-entry toc-h3"><a href="#mae">MAE</a></li>
<li class="toc-entry toc-h3"><a href="#rmsle">RMSLE</a>
<ul>
<li class="toc-entry toc-h4"><a href="#train">Train</a></li>
<li class="toc-entry toc-h4"><a href="#test">Test</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#classification-metrics-optimization">Classification Metrics Optimization</a>
<ul>
<li class="toc-entry toc-h3"><a href="#logloss-1">LogLoss</a></li>
<li class="toc-entry toc-h3"><a href="#auc">AUC</a></li>
<li class="toc-entry toc-h3"><a href="#f1-score-1">F1-Score</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#mean-encoding">Mean Encoding</a>
<ul>
<li class="toc-entry toc-h3"><a href="#ways-to-construct-mean-encoding">Ways to construct mean encoding</a></li>
<li class="toc-entry toc-h3"><a href="#possible-leaks">Possible Leaks</a></li>
<li class="toc-entry toc-h3"><a href="#regularization">Regularization</a>
<ul>
<li class="toc-entry toc-h4"><a href="#expanding-mean">Expanding Mean</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#regression">Regression</a></li>
</ul>
</li>
</ul><h1 id="how-to-win-a-data-science-competition-week-3">
<a class="anchor" href="#how-to-win-a-data-science-competition-week-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to win a data science competition (Week 3)</h1>

<h2 id="regression-metrics">
<a class="anchor" href="#regression-metrics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regression Metrics</h2>

<p><img src="https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Fi.stack.imgur.com%2F83BUy.png&amp;f=1" alt="Regression Metrics"></p>

<h3 id="mean-squared-error-mse">
<a class="anchor" href="#mean-squared-error-mse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mean Squared Error (MSE)</h3>

<ul>
  <li>MSE is the most commonly used metric</li>
  <li>Follows a <strong>parabolic curve</strong>
</li>
  <li>Optimal constant -&gt; Mean value of the target column</li>
  <li>Error is always greater than 0 and 0 for a perfect model</li>
  <li>Sensitive to outliers, as the values tend to be more biased towards the outliers</li>
</ul>

<h3 id="root-mean-squared-error-rmse">
<a class="anchor" href="#root-mean-squared-error-rmse" aria-hidden="true"><span class="octicon octicon-link"></span></a>Root Mean Squared Error (RMSE)</h3>

<ul>
  <li><code class="highlighter-rouge">RMSE = sqrt(MSE)</code></li>
  <li>Square root is taken to make the scale of the error same as the scale of the target</li>
  <li>Every minimiser of MSE is also a minimiser of RMSE i.e. MSE(a) &gt; MSE(b) implies RMSE(a) &gt; RMSE(b)</li>
  <li>We can minimise for MSE instead of RMSE; however this is not true for gradient based methods</li>
</ul>

<h3 id="r-squared">
<a class="anchor" href="#r-squared" aria-hidden="true"><span class="octicon octicon-link"></span></a>R-Squared</h3>

<ul>
  <li>It’s difficult to judge whether our model is good or bad just by looking at the values of MSE &amp; RMSE</li>
  <li>So, we should compare it against the baseline model which is mean for MSE &amp; RMSE
<img src="https://i.imgur.com/Lffwcqb.png" alt="R-squared">
    <ul>
      <li>When MSE is 0 ie the numerator is 0, then R-squared is 1</li>
      <li>When our model performs just like the baseline model or worse, then R-squared is 0</li>
    </ul>
  </li>
  <li>To minimise R-squared we can still minimise MSE</li>
</ul>

<h3 id="mean-absolute-error-mae">
<a class="anchor" href="#mean-absolute-error-mae" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mean Absolute Error (MAE)</h3>

<ul>
  <li>MAE is less sensitive than MSE for outliers</li>
  <li>Optimal constant -&gt; Median of the target column</li>
  <li>If there are outliers use MAE, but if there are unexpected values that is useful use MSE</li>
</ul>

<h3 id="mean-absolute-percentage-error-mape">
<a class="anchor" href="#mean-absolute-percentage-error-mape" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mean Absolute Percentage Error (MAPE)</h3>

<p><img src="https://i.imgur.com/YYMpqUY.jpg" alt="MAPE"></p>

<ul>
  <li>Mean Absolute Percentage Error (MAPE) is a weighted version of MAE</li>
  <li>Optimal constant (MAPE) =&gt; Weighted median of the target values</li>
  <li>MAPE is useful if you are interested in minimising the relative error rather than absolute error. For example, if the error between 9 &amp; 10 is much worse than error between 999 &amp; 1000, we can use this loss function</li>
  <li>MAPE is undefined when the actual value is 0</li>
  <li>MAPE values can grow very large if the actual values (denominator) themselves are very low</li>
  <li>MAPE is biased towards predictions that are lower than the actual values</li>
  <li>MAPEs greater than 100% can occur.</li>
</ul>

<p><strong>Example</strong></p>
<blockquote>
  <p>yhat=20, yact=10, n=1 then MAPE = 50%
yhat=10, yact=20, n=1 then MAPE = 100%</p>
</blockquote>

<h3 id="mean-squared-percentage-error-mspe">
<a class="anchor" href="#mean-squared-percentage-error-mspe" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mean Squared Percentage Error (MSPE)</h3>

<ul>
  <li>Mean Squared Percentage Error (MSPE) is a weighted version of MSE</li>
  <li>As the target value for both of them increases, the curves flatten out</li>
  <li>Optimal constant (MSPE) =&gt; Weighted mean of the target values</li>
</ul>

<h3 id="root-mean-square-logarithmic-error-rmsle">
<a class="anchor" href="#root-mean-square-logarithmic-error-rmsle" aria-hidden="true"><span class="octicon octicon-link"></span></a>Root Mean Square Logarithmic Error (RMSLE)</h3>

<p>[RMSLE](<a href="https://hrngok.github.io/posts/metrics/#Root-Mean-Squared-Logaritmic-Error-(RMSLE)">https://hrngok.github.io/posts/metrics/#Root-Mean-Squared-Logaritmic-Error-(RMSLE)</a></p>

<p><code class="highlighter-rouge">RMSLE = RMSE(log(y_true+1), log(y_pred+1))</code></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.metrics import mean_squared_log_error
np.sqrt(mean_squared_log_error(y_true, y_pred))
</code></pre></div></div>

<ul>
  <li>RMSE is the Root Mean Squared Error of the log-transformed predicted and log-transformed actual values.</li>
  <li>Works for non-negative values only. A constant is added to the predictions and actual values in case the values are 0 as logarithm(0) is not defined</li>
</ul>

<p><strong>When to Use?</strong></p>

<ul>
  <li>Cares about <em>relative error more than absolute error</em>
</li>
  <li>We don’t want to penalize big differences when both the predicted and the actual are big numbers.</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Acutal=30, Predicted=40, RMSE=10, RMSLE=0.27
Actual=300, Predicted=400, RMSE=100, RMSLE=0.28
</code></pre></div></div>

<ul>
  <li>We want to penalize under estimates more than over estimates</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Actual = 600, Predicted = 1000, RMSLE = 0.51
Actual = 1000, Predicted = 1400, RMSLE = 0.36

Sales &amp; Inventory products, where having extra supply might be more preferable to not being able to providing product as much as the demand
</code></pre></div></div>

<h3 id="poisson-loss">
<a class="anchor" href="#poisson-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Poisson Loss</h3>

<p>The Poisson loss is a loss function used for regression when modeling count data.
<img src="https://i.imgur.com/Ydl0D4l.png" alt="poisson_loss">
Use the Poisson loss when you believe that the target value comes from a Poisson distribution and want to model the rate parameter conditioned on some input. Example - number of customers entering a shop, number of emails in a day, etc</p>

<h2 id="regression-loss">
<a class="anchor" href="#regression-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regression Loss</h2>

<h3 id="huber-loss">
<a class="anchor" href="#huber-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Huber Loss</h3>

<p>Huber Loss is a combination of MAE &amp; MSE. It is quadratic for smaller errors and linear otherwise i.e it acts like MSE for error closer to 0 and like MAE elsewhere. It is <code class="highlighter-rouge">differentiable at 0</code> unlike MAE. How small that error has to be to make it quadratic depends on a hyperparameter, <code class="highlighter-rouge">𝛿</code> (delta). It approaches <strong>MAE when 𝛿 ~ 0 and MSE when 𝛿 ~ ∞.</strong></p>

<p><img src="https://miro.medium.com/max/1050/1*0eoiZGyddDqltzzjoyfRzA.png" alt="Huber Loss"></p>

<p><img src="https://miro.medium.com/max/1008/1*jxidxadWSMLvwLDZz2mycg.png" alt="Huber Loss"></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">huber</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">true</span><span class="o">-</span><span class="n">pred</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">delta</span> <span class="p">,</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">((</span><span class="n">true</span><span class="o">-</span><span class="n">pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">delta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">true</span> <span class="o">-</span> <span class="n">pred</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">delta</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<p>The downside being that we might need to train the hyper parameter 𝛿 (delta) which is an iterative process.</p>

<h3 id="log-cosh-loss">
<a class="anchor" href="#log-cosh-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Log Cosh Loss</h3>

<p>Log-cosh is the logarithm of the hyperbolic cosine of the prediction error.</p>

<p><img src="https://miro.medium.com/max/872/1*hj5n5273jYX7rclO7bnfJg.png" alt="Formula"></p>

<p>It acts like a <em>quadratic loss for smaller values of x</em> and <em>a shifted version of abs(x) for larger values of x</em>. It is also twice differentiable, which is very useful for methods like XGBoost which use Hessian matrix for optimisation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">logcosh</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">true</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="classification-metrics">
<a class="anchor" href="#classification-metrics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Classification Metrics</h2>

<ul>
  <li>Soft Labels - Classifier’s probability scores</li>
  <li>Hard Labels - Label associated with a prediction; usually argmax(soft_labels)</li>
</ul>

<h3 id="matthews-correlation-coefficient">
<a class="anchor" href="#matthews-correlation-coefficient" aria-hidden="true"><span class="octicon octicon-link"></span></a>Matthews Correlation Coefficient</h3>

<p><a href="https://lettier.github.io/posts/2016-08-05-matthews-correlation-coefficient.html">Matthews Correlation Coefficient</a></p>

<p><img src="https://latex2image.joeraut.com/output/img-39cca6d7337bc35d.png" alt="MCC"></p>

<ul>
  <li>Used for binary classification</li>
  <li>It is regarded as a balanced measure which can be used even if the <em>classes are of very different sizes.</em>
</li>
  <li><strong>MCC is in essence a correlation coefficient between the observed and predicted binary classifications</strong></li>
  <li>A coefficient of +1 represents a perfect prediction (<em>FP=FN=0</em>), 0 no better than random prediction and −1(<em>TP=TN=0</em>) indicates total disagreement between prediction and observation.</li>
  <li>MCC is also perfectly <em>symmetric</em>, so no class is more important than the other; if you switch the positive and negative, you’ll still get the same value.</li>
</ul>

<h3 id="f1-score">
<a class="anchor" href="#f1-score" aria-hidden="true"><span class="octicon octicon-link"></span></a>F1-Score</h3>

<p><a href="https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric">F1-Score</a></p>

<h4 id="precision">
<a class="anchor" href="#precision" aria-hidden="true"><span class="octicon octicon-link"></span></a>Precision</h4>

<p><img src="https://miro.medium.com/max/948/1*HGd3_eAJ3-PlDQvn-xDRdg.png" alt="Precision"></p>

<ul>
  <li>Precision talks about how precise/accurate your model is out of those predicted positive, how many of them are actual positive.</li>
  <li>
<em>Precision is a good measure to use if the cost of false positive is high</em> Eg. In a spam detector, if a non-spam mail is classified as spam, then the user might lose an important mail.</li>
</ul>

<h4 id="recall">
<a class="anchor" href="#recall" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recall</h4>

<p><img src="https://miro.medium.com/max/836/1*dXkDleGhA-jjZmZ1BlYKXg.png" alt="Recall"></p>

<ul>
  <li>Recall actually calculates how many of the actual positives our model capture <em>through labeling it as Positive</em>
</li>
  <li><em>Recall is a good measure to use if the cost of false negative is high</em></li>
</ul>

<h3 id="accuracy">
<a class="anchor" href="#accuracy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Accuracy</h3>

<ul>
  <li>It is the fraction of correctly classified objects</li>
  <li>The best constant for accuracy =&gt; Always predicting the class with highest frequency</li>
  <li>Accuracy also <em>doesn’t care how how confident the classifier is in the predictions</em> i.e. it doesn’t
care about the predicted class probabilities. It is harder to optimise and it only cares about the class labels.</li>
  <li>It is most used when all the classes are equally important.</li>
</ul>

<blockquote>
  <p>Accuracy = (TP + TN) / (TP + TN + FP + FN)</p>
</blockquote>

<h3 id="logloss">
<a class="anchor" href="#logloss" aria-hidden="true"><span class="octicon octicon-link"></span></a>LogLoss</h3>

<ul>
  <li>LogLoss cares about soft labels i.e. class probabilities. Log Loss takes into account the uncertainty of your prediction based on how much it varies from the actual label.</li>
  <li>
    <p>The probabilities always sum upto 1
<img src="http://wiki.fast.ai/images/math/8/a/a/8aa1e513366a2046bee816f7a0f8dd1c.png" alt="Log Loss"></p>

    <ul>
      <li>M - number of possible class labels (dog, cat, fish)</li>
      <li>log - the natural logarithm</li>
      <li>y - a binary indicator (0 or 1) of whether class label c is the correct classification for observation o</li>
      <li>p - the model’s predicted probability that observation o is of class c
<img src="http://wiki.fast.ai/images/4/43/Log_loss_graph.png" alt="Log Loss Plot">
</li>
    </ul>
  </li>
  <li>LogLoss hugely penalises wrong answers as can be seen in the above graph (actual class=1). As we move towards the correct prediction the loss decreases &amp; there’s an upward curve when we predict the class as 0</li>
  <li>Optimal Constant (LogLoss) =&gt; Set probabilities as frequency of the classes. [0.1, 0.9] if number of class1 samples is 10 and number of class2 samples is 90.</li>
</ul>

<h3 id="auc-roc">
<a class="anchor" href="#auc-roc" aria-hidden="true"><span class="octicon octicon-link"></span></a>AUC ROC</h3>

<ul>
  <li>Tries all possible values as threshold &amp; then aggregates their scores.</li>
  <li>Used only for binary tasks. Depends on the ordering of predictions, not on absolute values.</li>
  <li>ROC is a probability curve and AUC represents degree or measure of separability.</li>
  <li>Random prediction leads to AUC = 0.5</li>
</ul>

<h4 id="auc-roc-curve">
<a class="anchor" href="#auc-roc-curve" aria-hidden="true"><span class="octicon octicon-link"></span></a>AUC ROC Curve</h4>

<ul>
  <li>An ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives.</li>
</ul>

<h4 id="pairs-ordering">
<a class="anchor" href="#pairs-ordering" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pairs Ordering</h4>

<ul>
  <li>It is the ratio of correctly ordered pair upon total number of pairs. <em>Ordering/Sorting of samples based on score is important</em>.</li>
  <li>AUC is the probability that score for the false positive will be greater than the score for true positive.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">AUC</span> <span class="o">=</span> <span class="c1"># correctly ordered pairs / # total number of pairs
</span></code></pre></div></div>

<ul>
  <li>Example - Suppose the ordering based on probability score is [TP, FP, TP, TP, FP, FP] then there are 7 instances/pairs when score(FP) &gt; score(TP) out of 9 possible pairs. So, AUC = 7/9
    <ul>
      <li>TP is when a model has correctly classified a sample as positive class</li>
      <li>FP is when a model has wrongly classified a sample as positive class</li>
      <li>TN is when a model has correctly classified a sample as negative class</li>
      <li>FN is when a model has wrongly classified a sample as negative class</li>
    </ul>
  </li>
</ul>

<h4 id="quiz">
<a class="anchor" href="#quiz" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quiz</h4>

<p>How would multiplying all of the predictions from a given model by 2.0 (for example, if the model predicts 0.4, we multiply by 2.0 to get a prediction of 0.8) change the model’s performance as measured by AUC?</p>
<blockquote>
  <p>No change. AUC only cares about relative prediction scores. AUC is based on the relative predictions, so any transformation of the predictions that preserves the relative ranking has no effect on AUC. This is clearly not the case for other metrics such as squared error, log loss, or prediction bias (discussed later).</p>
</blockquote>

<p>LogLoss value for N number of classes with constant prediction.</p>
<blockquote>
  <p>log(N)</p>
</blockquote>

<h3 id="cohens-kappa">
<a class="anchor" href="#cohens-kappa" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cohen’s Kappa</h3>

<p>The Kappa statistic (or value) is a metric that compares an <strong>Observed Accuracy</strong> with an <strong>Expected Accuracy (random chance)</strong>. In addition, it takes into account random chance (agreement with a random classifier), which generally means it is less misleading than simply using accuracy as a metric.</p>

<p>The kappa statistic is often used as a measure of reliability between two human raters. In supervised learning, one of the raters reflects “ground truth”, and the other “rater” is the machine learning classifier.</p>
<blockquote>
  <p>Cohen’s Kappa = 1 - [(1 - accuracy) / (1 - baseline)]</p>
</blockquote>

<p>Alternativey, since <code class="highlighter-rouge">error=1 - accuracy</code>,</p>
<blockquote>
  <p>Cohen’s Kappa = 1 - (error / baseline_error)</p>
</blockquote>

<p>It can also, be written as -</p>
<blockquote>
  <p>Kappa = (Observed Accuracy - Expected Accuracy) / (1 - Expected Accuracy)</p>
</blockquote>

<p>Cohen’s Kappa ranges from [-1, 1]</p>

<h4 id="example">
<a class="anchor" href="#example" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example</h4>

<p>Assume Confusion Matrix for a binary classification task as follows</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: center">Cats</th>
      <th style="text-align: right">Dogs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cats</td>
      <td style="text-align: center">10</td>
      <td style="text-align: right">7</td>
    </tr>
    <tr>
      <td>Dogs</td>
      <td style="text-align: center">5</td>
      <td style="text-align: right">8</td>
    </tr>
  </tbody>
</table>

<p><strong>Observed Accuracy</strong></p>

<p>It is simply the number of instances that were classified correctly throughout the entire confusion matrix ie the number of instances when the ground truth and classifier both agreed to a particular class for a sample.</p>

<blockquote>
  <p>Total Number of Instances = 30
Observed Accuracy = (10+8 ) / 30 = 0.6</p>
</blockquote>

<p><strong>Expected Accuracy</strong></p>

<blockquote>
  <p>Marginal Frequency (Cats) = [(10+7) * (10+5)] / 30 = 8.5
Marginal Frequency (Dogs) = [(7+8) * (5+8)] / 30 = 6.5
Expected Accuracy = [Marginal Frequency (Cats) + Marginal Frequency (Dogs)] / 30 = 0.5</p>
</blockquote>

<p><strong>Kappa</strong></p>
<blockquote>
  <p>Kappa Score = (observed accuracy - expected accuracy)/(1 - expected accuracy)
Kappa Score = (0.60 - 0.50) / (1 - 0.50) = 0.20</p>
</blockquote>

<h3 id="quadratic-weighted-kappa">
<a class="anchor" href="#quadratic-weighted-kappa" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quadratic Weighted Kappa</h3>

<p><a href="http://kagglesolutions.com/r/evaluation-metrics--quadratic-weighted-kappa">Quadratic Weighted Kappa</a></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.metrics import cohen_kappa_score, confusion_matrix
qwk = cohen_kappa_score(actuals, preds, weights="quadratic")
</code></pre></div></div>

<h2 id="target--metric">
<a class="anchor" href="#target--metric" aria-hidden="true"><span class="octicon octicon-link"></span></a>Target &amp; Metric</h2>

<ul>
  <li>Target Metric is what we want to optimise. It is how the model is eventually evaluated.</li>
  <li><strong>But no one really knows how to optimise target metrics efficiently. So, instead, we use Loss Functions, which is easy to optimise. Example it is not easy to optimise Accuracy Score, so we optimise for LogLoss &amp; eventually evaluate our model using Accuracy Score.</strong></li>
  <li>However, sometimes, the models can however optimise target metrics directly example MSE, LogLoss.</li>
  <li>Sometimes it is not possible to optimise target metric directly but we can somehow preprocess the train data and use a model with a metric or loss function which is easy to optimise. For example, optimising MSPE or MAPE is not easy, but we can instead optimise MSE</li>
  <li>Sometimes, we will optimise incorrect metrics but we will post-process to fit evaluation metric better</li>
  <li>A technique that always works is early stopping. Suppose that we have to optimise for M2, but cannot optimise directly. So, we instead optimise for metric M1 and monitor metric M2 on validation set. We stop when the model starts overfitting on M2.</li>
</ul>

<h2 id="regression-metrics-optimization">
<a class="anchor" href="#regression-metrics-optimization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regression Metrics Optimization</h2>

<h3 id="mse">
<a class="anchor" href="#mse" aria-hidden="true"><span class="octicon octicon-link"></span></a>MSE</h3>

<p>Most of the libraries have MSE implemented as a loss function, so we can directly optimise for MSE. Synonyms - L2 Loss</p>

<ul>
  <li>Tree-Based :- LightGBM, RandomForest and XGBoost</li>
  <li>Linear-Model :- SGDRegressor, Vowpal Vabbit</li>
  <li>Neural Nets :- Pytorch, Keras, TF</li>
</ul>

<h3 id="mae">
<a class="anchor" href="#mae" aria-hidden="true"><span class="octicon octicon-link"></span></a>MAE</h3>

<p>MAE is another commonly used metric, so most of the libraries can optimise for MAE directly. Synonyms - L1 Loss, Quantile loss, Huber loss</p>

<ul>
  <li>Tree-Based :- LightGBM, RandomForest, <del>XGBoost</del>
</li>
  <li>Neural Nets :- Pytorch, Keras, TF</li>
</ul>

<h3 id="rmsle">
<a class="anchor" href="#rmsle" aria-hidden="true"><span class="octicon octicon-link"></span></a>RMSLE</h3>

<h4 id="train">
<a class="anchor" href="#train" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train</h4>

<ul>
  <li>Transform the target</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">z</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>Fit a model with MSE loss</li>
</ul>

<h4 id="test">
<a class="anchor" href="#test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test</h4>

<ul>
  <li>Transform the prediction probabilities back</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</code></pre></div></div>

<h2 id="classification-metrics-optimization">
<a class="anchor" href="#classification-metrics-optimization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Classification Metrics Optimization</h2>

<h3 id="logloss-1">
<a class="anchor" href="#logloss-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>LogLoss</h3>

<p>Similar to MSE in terms of popularity &amp; hence implemented in almost all the major libraries.</p>

<ul>
  <li>Tree-Based :- LightGBM and XGBoost</li>
  <li>Linear-Model :- SGDRegressor, Vowpal Vabbit</li>
  <li>Neural Nets :- Pytorch, Keras, TF</li>
</ul>

<h3 id="auc">
<a class="anchor" href="#auc" aria-hidden="true"><span class="octicon octicon-link"></span></a>AUC</h3>

<p>Optimise pairwise loss for optimising AUC</p>

<ul>
  <li>Tree-Based :- LightGBM and XGBoost</li>
  <li>Neural Nets :- Pytorch, Keras, TF</li>
</ul>

<h3 id="f1-score-1">
<a class="anchor" href="#f1-score-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>F1-Score</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def f1_metric(y_true, y_pred):
    y_pred = K.round(y_pred)
    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)
    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)
    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)
    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)

    p = tp / (tp + fp + K.epsilon())
    r = tp / (tp + fn + K.epsilon())

    f1 = 2*p*r / (p+r+K.epsilon())
    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)
    return K.mean(f1)

def f1_loss(y_true, y_pred):

    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)
    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)
    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)
    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)

    p = tp / (tp + fp + K.epsilon())
    r = tp / (tp + fn + K.epsilon())

    f1 = 2*p*r / (p+r+K.epsilon())
    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)
    return 1 - K.mean(f1)
</code></pre></div></div>

<h2 id="mean-encoding">
<a class="anchor" href="#mean-encoding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mean Encoding</h2>

<p><a href="https://maxhalford.github.io/blog/target-encoding-done-the-right-way/">Link 1</a>
<a href="https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study">Link 2</a></p>

<ul>
  <li>We encode each level of categorical variable with corresponding target mean.</li>
  <li>The more complicated and non linear is the feature target dependency more effective is mean encoding</li>
  <li>Greater the number of level in categorical features is a good indicator of using mean encodings</li>
  <li>Prone to overfitting if the levels in categorical features in train and test datasets are different</li>
  <li>Unlike other encoding techniques, <em>mean encoding imposes an ordering</em>
</li>
</ul>

<h3 id="ways-to-construct-mean-encoding">
<a class="anchor" href="#ways-to-construct-mean-encoding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Ways to construct mean encoding</h3>

<blockquote>
  <p>Likelihood = #ones / (#ones + #zeros)
Weight of Evidence = log(#ones / #zeros) * 100
Count = #ones
Difference = #ones - #zeros</p>
</blockquote>

<h3 id="possible-leaks">
<a class="anchor" href="#possible-leaks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Possible Leaks</h3>

<p>Calculate <code class="highlighter-rouge">means</code> only on the train data. Then calculate mean encodings using by applying map function on both the train &amp; test data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># col = categorical feature
# target = target column
</span><span class="n">means</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s">'_mean_target'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
<span class="n">val</span><span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s">'_mean_target'</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="regularization">
<a class="anchor" href="#regularization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regularization</h3>

<h4 id="expanding-mean">
<a class="anchor" href="#expanding-mean" aria-hidden="true"><span class="octicon octicon-link"></span></a>Expanding Mean</h4>

<ul>
  <li>Introduces least amount of leakage</li>
  <li>No hyper parameters to tune</li>
  <li>Built in CatBoost</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cumsum</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">col</span><span class="p">)[</span><span class="s">'target'</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span> <span class="o">-</span> <span class="n">train</span><span class="p">[</span><span class="s">'target'</span><span class="p">]</span>
<span class="n">cumcnt</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">cumcnt</span><span class="p">()</span>
<span class="n">train_new</span><span class="p">[</span><span class="n">col</span><span class="o">+</span><span class="s">'_mean_target'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumsum</span><span class="o">/</span><span class="n">cumcnt</span>
</code></pre></div></div>

<h2 id="regression">
<a class="anchor" href="#regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regression</h2>

<p>Encode your categorical variable with the mean of the target. For every category, you calculate the corresponding mean of the target (among this category) and replace the value of a category with this mean. More flexible compared to classification tasks as you can use a variety of statistics like median, standard deviations, percentiles, etc.</p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="adimyth/notes"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/notes/evaluation%20metrics/losses/datascience/kaggle/2019/06/26/week3.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/notes/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/notes/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Aditya Mishra</li>
          <li><a class="u-email" href="mailto:mishraaditya6991@gmail.com">mishraaditya6991@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p>Documenting all my learning notes here. Contains notes from different MOOCs, Blogs &amp; Other YouTube Videos.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/adimyth" title="adimyth"><svg class="svg-icon grey"><use xlink:href="/notes/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/adi_myth" title="adi_myth"><svg class="svg-icon grey"><use xlink:href="/notes/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
